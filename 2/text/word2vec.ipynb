{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# pip install gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65075\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from gensim.parsing import PorterStemmer\n",
    "global_stemmer = PorterStemmer()\n",
    "\n",
    "def stem(word):\n",
    "    return global_stemmer.stem(word)\n",
    "    \n",
    "texts = [r\"D:\\nltk_data\\corpora\\gutenberg\\carroll-alice.txt\", \n",
    "         r\"D:\\nltk_data\\corpora\\gutenberg\\melville-moby_dick.txt\",\n",
    "         r\"D:\\nltk_data\\corpora\\gutenberg\\edgeworth-parents.txt\",\n",
    "         r\"D:\\nltk_data\\corpora\\gutenberg\\austen-emma.txt\",\n",
    "         r\"D:\\nltk_data\\corpora\\gutenberg\\whitman-leaves.txt\",\n",
    "        ]\n",
    "\n",
    "sentences = []\n",
    "for text in texts:\n",
    "    paragraphs = open(text, 'r').read().split('\\n')\n",
    "    for paragraph in paragraphs:\n",
    "        if not paragraph:\n",
    "            continue\n",
    "        words = re.split('\\W+', paragraph)\n",
    "        stems = list(map(stem, words))\n",
    "        sentences.append(stems)\n",
    "\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_count – Terms that occur less than min_count number of times are ignored in the calculations.\n",
    "min_count = 2\n",
    "# size – Denotes the number of dimensions present in the vectorial forms\n",
    "size = 50\n",
    "# window – Only terms occured within a window-neighbourhood of a term, in a sentence, are associated with it during training\n",
    "window = 5\n",
    "# sg – This defines the algorithm. If equal to 1, the skip-gram technique is used. Else, the CBoW method is employed\n",
    "sg = 2\n",
    " \n",
    "model = Word2Vec(sentences, min_count=min_count, size=size, window=window, sg=sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02284084  0.00219427  0.04516478 -0.09627176 -0.17068847  0.20790187\n",
      "  0.35279182  0.13830213  0.2937018   0.20648181  0.06493118  0.13437545\n",
      " -0.08216808  0.44094601 -0.0120792   0.32856193 -0.11439771 -0.12413667\n",
      " -0.21969607  0.38249594 -0.72942311 -0.06320293 -0.12884344  0.0514037\n",
      "  0.06247916 -0.43638936  0.66610157  0.07403175 -0.0815038  -0.16886216\n",
      " -0.04215846 -0.11558484 -0.03844558  0.19592835  0.26609114  0.32047987\n",
      "  0.26128998  0.13215984 -0.17001654  0.32539719 -0.1452145   0.02446866\n",
      "  0.16743334  0.0222801  -0.07679017 -0.11784447  0.02169158 -0.27806392\n",
      "  0.38391161 -0.06749401]\n"
     ]
    }
   ],
   "source": [
    "# get vector\n",
    "print(model.wv[stem(\"flower\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('slope', 0.9541400074958801) ('marbl', 0.9455724358558655) ('huge', 0.9453623294830322) ('branch', 0.9445964097976685) ('mist', 0.9433178901672363) ('orchard', 0.9425175786018372) ('shower', 0.9408861994743347) ('flake', 0.9396103620529175) ('plate', 0.939597487449646) ('tent', 0.9387097358703613) \n",
      "\n",
      "('mous', 0.899776816368103) ('hal', 0.898469090461731) ('franklin', 0.8963371515274048) ('sigh', 0.8929925560951233) ('laura', 0.8730060458183289) ('cecilia', 0.8673756718635559) ('earnestli', 0.8614912033081055) ('jem', 0.8592300415039062) ('louisa', 0.8588223457336426) ('felix', 0.8587736487388611) \n",
      "\n",
      "('queen', 0.9533609747886658) ('charm', 0.9431209564208984) ('sweeper', 0.9360947012901306) ('innoc', 0.9350640177726746) ('cousin', 0.9324368238449097) ('sweepstak', 0.9317840933799744) ('loudli', 0.9317439794540405) ('bride', 0.9290064573287964) ('juri', 0.9278756380081177) ('cox', 0.9268172979354858)\n",
      "0.795907969583\n",
      "0.554903223166\n"
     ]
    }
   ],
   "source": [
    "# latent space arithmetics\n",
    "print(*model.wv.most_similar(stem('flower')), '\\n')\n",
    "print(*model.wv.most_similar(positive=[stem('alice')]), '\\n')\n",
    "# classical example of w2v\n",
    "print(*model.wv.most_similar_cosmul(positive=['woman', 'king'], negative=['man']))\n",
    "\n",
    "print(model.wv.similarity(stem(\"walk\"), stem(\"went\")))\n",
    "print(model.wv.similarity(stem(\"walk\"), stem(\"cat\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
